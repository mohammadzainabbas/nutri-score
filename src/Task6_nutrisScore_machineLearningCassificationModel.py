# -*- coding: utf-8 -*-
"""NutriScore_MachineLearningCassificationModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wNb-EtKSZBaByn_mJkjZX8XvSByhQNLL
"""

!git clone https://github.com/mohammadzainabbas/nutri-score.git

"""# import the products data"""

import pandas as pd
import numpy as np

import math

from sklearn.metrics import accuracy_score

    
class Read_Data():
    def __init__(self, data_path):
        self.data = pd.read_csv(data_path)
        self.cols = ['id', 'name', 'category', 'en', 'su', 'fa', 'sa', 'pr', 'fi', 'fr', 'grade']
        self.init_cols = ['id', 'name', 'categories', 'energy', 'sugars' ,'saturated-fat','salt', 'proteins',
        'fiber','fruits-vegetables-nuts-estimate-from-ingredients_100g','grade']
    
    def getCols(self):
        self.data = self.data.loc[:, self.init_cols].copy()
        self.data.columns = self.cols
    
    def setNans(self):
        self.data.dropna(inplace=True)
    
    def setNegValues(self):
        self.data.en = self.data.en * -1
        self.data.su = self.data.su * -1
        self.data.fa = self.data.fa * -1
        self.data.sa = self.data.sa * -1
    
    def getData(self):
        self.getCols()
        self.setNans()
        self.setNegValues()
        
        return self.data

    
# pass the data directory to Read_Data class
rd = Read_Data("/content/nutri-score/data/products.csv")

# call the getData() to return dataframe
df = rd.getData()
df

from sklearn import preprocessing
le = preprocessing.LabelEncoder()
le.fit(["a", "b", "c", "d", "e"])
y_train=le.transform(df[['grade']])
#y_train=df.iloc[:,10]
X_train=df.iloc[:,3:10]

"""# decision tree

The accuracy_score returns the fraction of correctly classified samples (float).
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
clf_en = DecisionTreeClassifier(criterion='entropy', max_depth=7, random_state=0)
clf_en.fit(X_train, y_train)
y_pred_en = clf_en.predict(X_train)
print(accuracy_score(y_train, y_pred_en))

"""# random forest

The accuracy_score returns the fraction of correctly classified samples (float).
"""

from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(max_depth=5, random_state=0)
clf.fit(X_train, y_train)
y_pred_en=clf.predict(X_train)
print(accuracy_score(y_train, y_pred_en))

"""# logistic regression

The accuracy_score returns the fraction of correctly classified samples (float).
"""

from sklearn.linear_model import LogisticRegression
lr=LogisticRegression()
lr.fit(X_train, y_train)
y_pred_en=lr.predict(X_train)
print(accuracy_score(y_train, y_pred_en))

"""# Naive Bayes

Naive Bayes algorithm based on Bayesâ€™ theorem with the assumption of independence between every pair of features. 
"""

from sklearn.naive_bayes import GaussianNB
nb=GaussianNB()
nb.fit(X_train, y_train)
y_pred_en=nb.predict(X_train)
print(accuracy_score(y_train, y_pred_en))

"""# K-Nearest Neighbours"""

from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier(n_neighbors=15)
knn.fit(X_train, y_train)
y_pred_en=knn.predict(X_train)
print(accuracy_score(y_train, y_pred_en))